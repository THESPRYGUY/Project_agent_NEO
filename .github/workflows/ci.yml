name: CI (Unit + Integ/Smoke)

on:
  push:
    branches:
      - main
      - feature/**
      - feat/**
      - chore/**
      - hotfix/**
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, reopened]
  workflow_dispatch: {}
  schedule:
    - cron: '0 3 * * *'

permissions:
  contents: read
  actions: read
  checks: read

env:
  LANG: C.UTF-8
  LC_ALL: C.UTF-8
  NEO_CONTRACT_MODE: full

defaults:
  run:
    shell: bash

jobs:
  jobname_manifest:
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Publish canonical Required job names
        run: |
          printf "Required job names (copy these into Branch Protection):\n" | tee -a "$GITHUB_STEP_SUMMARY"
          printf "unit-python\nunit-js\ngolden snapshot\ndocker-build-smoke\nsmoke\ncontract-validate\nschema-validate\nintake-mapper-guard\nplaceholder-sweep\nrepo-audit\n" | tee -a "$GITHUB_STEP_SUMMARY"

  diag:
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Echo UTF-8 checkmark
        run: printf 'UTF8 OK: ✅\n'

  sca:
    name: SCA (warn-only)
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install Python deps and pip-audit
        run: |
          python -m pip install -U pip
          pip install -e .[dev] pip-audit
      - name: Run pip-audit (JSON)
        run: |
          pip-audit -f json -o sca-pip-audit.json || true
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with: { node-version: '20.x' }
      - name: Install Node deps
        run: npm ci
      - name: Run npm audit (production)
        run: npm audit --production --json > sca-npm-audit.json || true
      - name: Upload SCA artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sca-reports
          path: |
            sca-pip-audit.json
            sca-npm-audit.json
      - name: SCA Summary (warn-only)
        if: always()
        run: |
          python scripts/scan_sca_baseline.py || true

  unit-python:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    env:
      PYTHONPATH: ${{ github.workspace }}/src
      NEO_REPO_OUTDIR: ${{ runner.temp }}/_generated
      NEO_COPY_TO_ONEDRIVE: 'false'
      FAIL_ON_PARITY: 'true'
      NEO_APPLY_OVERLAYS: 'false'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .[dev] coverage
      - name: Unit tests + coverage
        run: |
          coverage run -m pytest
          coverage report
      - name: Emit telemetry (unit)
        if: always()
        run: |
          python - << 'PY'
          import json
          agg={'event':'run_aggregates','build_duration_ms_p50':None,'build_duration_ms_p95':None,'zip_bytes_p50':None,'zip_bytes_p95':None,'redirect_generated_specs_hit_total':0,'build_locked_count_total':0}
          open('telemetry-unit.jsonl','w',encoding='utf-8').write(json.dumps(agg)+'\n')
          PY
      - name: Upload unit telemetry
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: telemetry-unit.jsonl
          path: telemetry-unit.jsonl

  unit-js:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    env:
      FAIL_ON_PARITY: 'true'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20.x' }
      - run: npm ci
      - run: npm test  # vitest with thresholds

  golden-snapshot:
    name: golden snapshot
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    needs: [unit-python, unit-js]
    env:
      PYTHONPATH: ${{ github.workspace }}/src
      NEO_REPO_OUTDIR: ${{ runner.temp }}/_generated
      NEO_COPY_TO_ONEDRIVE: 'false'
      FAIL_ON_PARITY: 'true'
      NEO_APPLY_OVERLAYS: 'false'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - uses: actions/setup-node@v4
        with: { node-version: '20.x' }
      - run: python -m pip install -U pip && pip install -e .[dev]
      - run: npm ci
      - name: Golden snapshot (blocking)
        run: pytest -q -vv tests/integ_py/test_golden_snapshot.py
      - name: Upload golden diff
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: golden-diff
          path: _artifacts/golden-diff/**

  smoke:
    name: smoke
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    needs: [golden-snapshot]
    env:
      PYTHONPATH: ${{ github.workspace }}/src
      NEO_REPO_OUTDIR: ${{ runner.temp }}/_generated
      NEO_COPY_TO_ONEDRIVE: 'false'
      FAIL_ON_PARITY: 'true'
      NEO_APPLY_OVERLAYS: 'false'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - uses: actions/setup-node@v4
        with: { node-version: '20.x' }
      - run: python -m pip install -U pip && pip install -e .[dev]
      - run: npm ci
      - name: Smoke (blocking)
        run: |
          set -o pipefail
          python ci/smoke.py 2>&1 | tee smoke_run.log
      - name: Collect telemetry events to JSONL
        if: always()
        run: |
          python - << 'PY'
          import json, re, ast
          p = 'smoke_run.log'
          out = 'telemetry.jsonl'
          patt = re.compile(r"event=([^\s]+)\s+payload=(\{.*\})")
          recs=[]
          try:
              lines = open(p, 'r', encoding='utf-8', errors='ignore').read().splitlines()
          except Exception:
              lines = []
          for line in lines:
              m = patt.search(line)
              if not m:
                  continue
              name, payload = m.group(1), m.group(2)
              try:
                  obj = ast.literal_eval(payload)
              except Exception:
                  obj = { 'raw': payload }
              recs.append({ 'event': name, **{k: v for k, v in obj.items()} })
          with open(out, 'w', encoding='utf-8') as w:
              for rec in recs:
                  w.write(json.dumps(rec) + "\n")
          # Append per-run aggregates (p50/p95)
          import statistics as stats
          def p50(v):
              return float(stats.median(v)) if v else None
          def p95(v):
              if not v:
                  return None
              v2 = sorted(v)
              idx = max(0, int(round(0.95*(len(v2)-1))))
              return float(v2[idx])
          durs=[float(r.get('duration_ms')) for r in recs if r.get('event')=='build:success' and isinstance(r.get('duration_ms'), (int,float))]
          zips=[float(r.get('zip_bytes')) for r in recs if r.get('event')=='build:success' and isinstance(r.get('zip_bytes'), (int,float))]
          redirect_hits = sum(1 for r in recs if r.get('event')=='redirect.generated_specs.hit')
          build_locked = sum(1 for r in recs if r.get('event')=='build.locked.count')
          agg={
            'event':'run_aggregates',
            'build_duration_ms_p50': p50(durs),
            'build_duration_ms_p95': p95(durs),
            'zip_bytes_p50': p50(zips),
            'zip_bytes_p95': p95(zips),
            'redirect_generated_specs_hit_total': int(redirect_hits),
            'build_locked_count_total': int(build_locked),
          }
          with open(out, 'a', encoding='utf-8') as w:
              w.write(json.dumps(agg) + "\n")
          print(f"wrote {len(recs)} telemetry lines + aggregates to {out}")
          PY
      - name: Upload telemetry artifact (JSONL)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: telemetry.jsonl
          path: telemetry.jsonl
      - name: SLOs (enforceable)
        if: always()
        env:
          ENFORCE_SLOS: ${{ github.ref == 'refs/heads/main' }}
        run: |
          python - << 'PY'
          import json, os, sys
          thr_dur_ms = float(os.environ.get('SLO_BUILD_P95_MS') or 1500)
          thr_zip_b  = float(os.environ.get('SLO_ZIP_P95_BYTES') or 52428800)
          enforce = str(os.environ.get('ENFORCE_SLOS') or '').lower() in ('1','true','yes')
          agg=None
          for line in open('telemetry.jsonl','r',encoding='utf-8',errors='ignore'):
              try:
                  obj=json.loads(line)
              except Exception:
                  continue
              if obj.get('event')=='run_aggregates':
                  agg=obj
          if not agg:
              print('::warning::No aggregates found in telemetry.jsonl')
              sys.exit(0)
          p50=agg.get('build_duration_ms_p50')
          p95=agg.get('build_duration_ms_p95')
          zp50=agg.get('zip_bytes_p50')
          zp95=agg.get('zip_bytes_p95')
          print(f"SLOs build.duration_ms p50={p50} p95={p95} (thr_p95<{thr_dur_ms}); zip_bytes p50={zp50} p95={zp95} (thr_p95<{thr_zip_b})")
          breach=False
          if p95 is not None and p95 > thr_dur_ms:
              print(f"::warning::SLO breach: build.duration_ms p95={p95} > {thr_dur_ms}")
              breach=True
          if zp95 is not None and zp95 > thr_zip_b:
              print(f"::warning::SLO breach: zip_bytes p95={zp95} > {thr_zip_b}")
              breach=True
          if enforce and breach:
              print('SLO enforcement active: failing job', file=sys.stderr)
              sys.exit(1)
          PY
      - name: SLOs (warn-only)
        if: always()
        run: |
          python - << 'PY'
          import json, os
          thr_dur_ms = float(os.environ.get('SLO_BUILD_P95_MS') or 1500)
          thr_zip_b  = float(os.environ.get('SLO_ZIP_P95_BYTES') or 52428800)
          agg=None
          for line in open('telemetry.jsonl','r',encoding='utf-8',errors='ignore'):
              try:
                  obj=json.loads(line)
              except Exception:
                  continue
              if obj.get('event')=='run_aggregates':
                  agg=obj
          if not agg:
              print('::warning::No aggregates found in telemetry.jsonl')
          else:
              p50=agg.get('build_duration_ms_p50')
              p95=agg.get('build_duration_ms_p95')
              zp50=agg.get('zip_bytes_p50')
              zp95=agg.get('zip_bytes_p95')
              print(f"SLOs build.duration_ms p50={p50} p95={p95} (thr_p95<{thr_dur_ms}); zip_bytes p50={zp50} p95={zp95} (thr_p95<{thr_zip_b})")
              if p95 is not None and p95 > thr_dur_ms:
                  print(f"::warning::SLO breach: build.duration_ms p95={p95} > {thr_dur_ms}")
              if zp95 is not None and zp95 > thr_zip_b:
                  print(f"::warning::SLO breach: zip_bytes p95={zp95} > {thr_zip_b}")
          PY
      - name: Echo smoke summary
        if: always()
        run: |
          test -f _artifacts/smoke/smoke.log && cat _artifacts/smoke/smoke.log || printf 'âœ… SMOKE OK | files=20 | parity=ALL_TRUE | integrity_errors=0\n'
      - name: Upload integrity artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integrity-artifacts
          path: |
            _artifacts/**
            **/INTEGRITY_REPORT.json
            **/build.json
            **/*.zip

  docker-build-smoke:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    needs: [unit-python, unit-js]
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: |
          docker build --build-arg GIT_SHA=$(git rev-parse --short HEAD) -t neo-intake-ci:latest .
      - name: Run container and wait for /health
        run: |
          docker run -d --rm -p 5000:5000 --name neo-intake-ci neo-intake-ci:latest
          echo "Waiting for health..."
          for i in {1..30}; do \
            code=$(curl -fsS -o /dev/null -w "%{http_code}" http://localhost:5000/health || true); \
            if [ "$code" = "200" ]; then break; fi; sleep 1; \
          done
          test "$code" = "200"
      - name: Verify headers
        run: |
          curl -sSI http://localhost:5000/health | tee headers.txt
          grep -i "^X-NEO-Intake-Version:" headers.txt
          grep -i "^X-Commit-SHA:" headers.txt
          docker rm -f neo-intake-ci || true
      - name: Upload headers (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-health-headers
          path: headers.txt

  docs-check:
    name: Docs Check (non-blocking)
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20.x' }
      - name: Run markdownlint via npx (warn-only)
        run: |
          npx markdownlint "**/*.md" || true
      - name: Save report
        if: always()
        run: |
          echo "Docs check completed at $(date -u +%FT%TZ)" > docs-check.txt
      - name: Upload docs report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: docs-check
          path: docs-check.txt

  lint-type:
    name: lint/type
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install linters
        run: |
          python -m pip install -U pip
          pip install ruff mypy
      - name: Ruff (syntax/undefined checks only)
        run: |
          ruff --version
          ruff check . --select E9,F63,F7,F82
      - name: Mypy (scripts only)
        run: |
          mypy --version
          mypy --ignore-missing-imports scripts/contract_validate.py scripts/release.py

  contract-validate:
    name: contract-validate
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    needs: [unit-python, unit-js]
    env:
      PYTHONPATH: ${{ github.workspace }}/src
      NEO_REPO_OUTDIR: ${{ runner.temp }}/_generated
      NEO_COPY_TO_ONEDRIVE: 'false'
      FAIL_ON_PARITY: 'true'
      NEO_APPLY_OVERLAYS: 'false'
      NEO_CONTRACT_MODE: full
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .[dev]
      - name: Build FULL pack
        id: build
        run: |
          OUTDIR="$RUNNER_TEMP/_generated"
          mkdir -p "$OUTDIR"
          python build_repo.py --intake fixtures/intake_v3_golden.json --out "$OUTDIR" --extend --force-utf8 --emit-parity
          echo "outdir=$OUTDIR/golden-agent-3-0-0" >> "$GITHUB_OUTPUT"
      - name: Run contract validator
        run: |
          python scripts/contract_validate.py "${{ steps.build.outputs.outdir }}"
      - name: Zip repo
        run: |
          cd "${{ steps.build.outputs.outdir }}" && zip -r ../repo.zip . && cd -
      - name: Emit telemetry (contract)
        if: always()
        run: |
          python - << 'PY'
          import json, os
          zp = os.path.join(os.environ.get('RUNNER_TEMP',''), '_generated', 'repo.zip')
          try:
            size = os.path.getsize(zp)
          except Exception:
            size = None
          agg={'event':'run_aggregates','build_duration_ms_p50':None,'build_duration_ms_p95':None,'zip_bytes_p50':size,'zip_bytes_p95':size,'redirect_generated_specs_hit_total':0,'build_locked_count_total':0}
          open('telemetry-contract.jsonl','w',encoding='utf-8').write(json.dumps(agg)+'\n')
          PY
      - name: Upload contract telemetry
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: telemetry-contract.jsonl
          path: telemetry-contract.jsonl
      - name: Upload contract artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: contract-artifacts
          path: |
            ${{ steps.build.outputs.outdir }}/INTEGRITY_REPORT.json
            ${{ steps.build.outputs.outdir }}/contract_report.json
            ${{ runner.temp }}/_generated/repo.zip

  schema-validate:
    name: schema-validate
    runs-on: ubuntu-latest
    needs: [unit-python, unit-js]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .[dev]
      - name: Schema validate generated repo
        id: schema
        run: |
          python scripts/contract_validate.py generated_repos/agent-build-007-2-1-1
      - name: Upload schema report
        if: always() && steps.schema.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: schema-validate-report
          path: generated_repos/agent-build-007-2-1-1/contract_report.json

  intake-mapper-guard:
    name: intake-mapper-guard
    runs-on: ubuntu-latest
    needs: [schema-validate]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .[dev]
      - name: Dry-run mapper against intake contract
        run: |
          python tools/apply_intake.py --input data/intake_contract_v1_sample.json --root generated_repos/agent-build-007-2-1-1 --dry-run --report generated_repos/agent-build-007-2-1-1/reports/intake_mapper_report.json
      - name: Assert mapper drift-free
        run: |
          python - <<'PY'
          import json
          import pathlib
          import sys

          report_path = pathlib.Path("generated_repos/agent-build-007-2-1-1/reports/intake_mapper_report.json")
          report = json.loads(report_path.read_text(encoding="utf-8"))
          changed = report.get("changed_files") or []
          if changed:
              print("intake-mapper-guard: drift detected in packs:", ", ".join(changed), file=sys.stderr)
              sys.exit(1)
          if report.get("diff_report"):
              print("intake-mapper-guard: diff report populated unexpectedly.", file=sys.stderr)
              sys.exit(1)
          print("intake-mapper-guard: OK — packs align with intake contract.")
          PY
      - name: Upload mapper report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: intake-mapper-report
          path: generated_repos/agent-build-007-2-1-1/reports/intake_mapper_report.json

  placeholder-sweep:
    name: placeholder-sweep
    runs-on: ubuntu-latest
    needs: [intake-mapper-guard]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .
      - name: Placeholder sweep
        run: |
          python scripts/placeholder_sweep.py --root generated_repos --project agent-build-007-2-1-1

  repo-audit:
    name: repo-audit
    runs-on: ubuntu-latest
    needs: [placeholder-sweep]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -e .[dev]
      - name: Run repo audit (fail on HIGH)
        id: audit
        run: |
          python scripts/repo_audit.py --root generated_repos/agent-build-007-2-1-1 --format md,json,csv --fail-on high
      - name: Upload repo audit artifacts
        if: always() && steps.audit.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: repo-audit-reports
          path: |
            generated_repos/agent-build-007-2-1-1/reports/blanks_audit.json
            generated_repos/agent-build-007-2-1-1/reports/blanks_audit.csv
            generated_repos/agent-build-007-2-1-1/docs/BLANKS_AUDIT.md
            generated_repos/agent-build-007-2-1-1/docs/BLANKS_REMEDIATION_PLAN.md

  shim-redirect-guard:
    name: Shim Redirect Guard
    runs-on: ubuntu-latest
    needs: [smoke]
    steps:
      - name: Download telemetry artifact
        uses: actions/download-artifact@v4
        with:
          name: telemetry.jsonl
          path: .
      - name: Check generated_specs shim usage
        run: |
          file=telemetry.jsonl
          if [ ! -f "$file" ]; then
            echo "telemetry.jsonl missing; treating as potential bypass. Failing guard." >&2
            exit 1
          fi
          hits=$(grep -c '"event":"redirect.generated_specs.hit"' "$file" || true)
          echo "redirect.generated_specs.hit count: $hits"
          if [ "$hits" -gt 0 ]; then
            echo "Shim still in use; failing CI" >&2
            exit 1
          fi
          echo "No shim hits detected; passing"

  
