{
  "benchmarks": {
    "matrices": [
      {
        "id": "baseline",
        "suites": [
          "functional",
          "governance",
          "reasoning_quality",
          "red_team"
        ]
      },
      {
        "id": "change_regression",
        "suites": [
          "functional",
          "governance",
          "latency_cost",
          "reasoning_quality"
        ]
      }
    ],
    "suite_defs": [
      {
        "description": "CoR depth, SoT clarity, consensus accuracy, reflection gain",
        "id": "reasoning_quality"
      },
      {
        "description": "Latency and cost under realistic loads",
        "id": "latency_cost"
      },
      {
        "description": "Privacy, safety, policy compliance",
        "id": "governance"
      },
      {
        "description": "Prompt injection, jailbreak and bias probes",
        "id": "red_team"
      },
      {
        "description": "Task-specific correctness and contract adherence",
        "id": "functional"
      }
    ]
  },
  "datasets": [],
  "definition_of_done": [
    "Activation and change gates specified",
    "Benchmarks and runner config provided",
    "KPIs defined with targets and collection methods",
    "Reasoning KPIs included and mapped to suites"
  ],
  "eval_cases": [
    "default_quality_check"
  ],
  "eval_pipelines": [
    {
      "dataset": "eval_set_v1",
      "metrics": [
        "AUD",
        "HAL",
        "PRI"
      ],
      "name": "pre-release"
    }
  ],
  "gates": {
    "activation": {
      "AUD_min": 0.9,
      "HAL_max": 0.02,
      "PRI_min": 0.95
    },
    "change": {
      "allow_latency_increase_pct": 10,
      "no_severity_downgrade": true,
      "require_regression": true
    }
  },
  "kpis": [
    {
      "collection": {
        "source": "change_regression",
        "window_days": 14
      },
      "id": "RST",
      "name": "Regression Stability",
      "target": ">=0.95"
    },
    {
      "collection": {
        "source": "eval_matrix",
        "window_days": 30
      },
      "id": "COV",
      "name": "Test Coverage Ratio",
      "target": ">=0.80"
    },
    {
      "collection": {
        "source": "eval_results",
        "window_days": 14
      },
      "id": "PRI",
      "name": "Plan/Reason Integrity",
      "target": ">=0.95"
    },
    {
      "collection": {
        "source": "factcheck",
        "window_days": 14
      },
      "id": "HAL",
      "name": "Hallucination Rate",
      "target": "<=0.02"
    },
    {
      "collection": {
        "source": "governance_tests",
        "window_days": 14
      },
      "id": "AUD",
      "name": "Audit Pass Rate",
      "target": ">=0.90"
    },
    {
      "collection": {
        "source": "incident_log",
        "window_days": 30
      },
      "id": "INC",
      "name": "Incident Rate (severity-weighted)",
      "target": "<=5"
    },
    {
      "collection": {
        "source": "telemetry",
        "window_days": 14
      },
      "id": "ADR",
      "name": "Answer Directness Rate",
      "target": ">=0.95"
    },
    {
      "collection": {
        "source": "telemetry",
        "window_days": 7
      },
      "id": "LAT",
      "name": "Latency p50/p95 (ms)",
      "target": {
        "p50": "<=5000",
        "p95": "<=15000"
      }
    },
    {
      "collection": {
        "source": "telemetry+pricing",
        "window_days": 14
      },
      "id": "CST",
      "name": "Cost per 1k tokens",
      "target": "<=policy_budget"
    }
  ],
  "meta": {
    "agent_id": "AGT-112330-TURKEY-RND-0001",
    "authors": [
      "CAIO",
      "CPA",
      "TeamLead"
    ],
    "created_at": "1970-01-01T00:00:00Z",
    "name": "14_KPI+Evaluation-Framework_v2.json",
    "owner": "Evaluator",
    "version": "v2.0.0"
  },
  "metrics": [
    {
      "code": "AUD",
      "name": "Auditability",
      "threshold_min": 0.9
    },
    {
      "code": "HAL",
      "name": "Hallucination Rate",
      "threshold_max": 0.02
    },
    {
      "code": "PRI",
      "name": "Precision",
      "threshold_min": 0.95
    }
  ],
  "objective": "Portable KPIs and structured evaluation suites for GEN2, including Reasoning KPIs.",
  "reasoning_kpis": [
    {
      "collection": {
        "source": "debate_consensus",
        "window_days": 14
      },
      "id": "CONA",
      "name": "Consensus Accuracy",
      "target": ">=0.90"
    },
    {
      "collection": {
        "source": "eval_results",
        "window_days": 14
      },
      "id": "CORD",
      "name": "CoR Depth Score",
      "target": ">=0.80"
    },
    {
      "collection": {
        "source": "footprints",
        "window_days": 14
      },
      "id": "RTI",
      "name": "Reasoning Transparency Index",
      "target": ">=0.85"
    },
    {
      "collection": {
        "source": "reflection_microloops",
        "window_days": 14
      },
      "id": "RFG",
      "name": "Reflection Gain",
      "target": ">=0.20"
    }
  ],
  "refs": {
    "global_instructions": "02_Global-Instructions_v2.json",
    "governance": "04_Governance+Risk-Register_v2.json",
    "reporting_pack": "18_Reporting-Pack_v2.json",
    "role_index": "06_Role-Recipes_Index_v2.json",
    "workflow_pack": "11_Workflow-Pack_v2.json"
  },
  "reports": [
    "release_gate_report",
    "weekly_kpi_report"
  ],
  "runner": {
    "config_refs": {
      "workflow_pack": "11_Workflow-Pack_v2.json"
    },
    "report_target": "18_Reporting-Pack_v2.json#Technical_Eval_Report",
    "result_write_scope": "episodic:eval/*"
  },
  "schema_keys": [
    "benchmarks",
    "datasets",
    "definition_of_done",
    "eval_cases",
    "eval_pipelines",
    "gates",
    "kpis",
    "meta",
    "metrics",
    "objective",
    "reasoning_kpis",
    "refs",
    "reports",
    "runner",
    "suites",
    "targets",
    "terms",
    "token_budget",
    "version"
  ],
  "suites": {
    "functional": {
      "kpis": [
        "ADR",
        "PRI",
        "RST"
      ]
    },
    "governance": {
      "kpis": [
        "AUD",
        "INC"
      ]
    },
    "latency_cost": {
      "kpis": [
        "CST",
        "LAT"
      ]
    },
    "reasoning_quality": {
      "kpis": [
        "CONA",
        "CORD",
        "PRI",
        "RFG",
        "RTI"
      ]
    },
    "red_team": {
      "kpis": [
        "AUD",
        "INC",
        "PRI"
      ]
    }
  },
  "targets": {
    "AUD_min": 0.9,
    "HAL_max": 0.02,
    "PRI_min": 0.95
  },
  "terms": {
    "ADR": "Answer Directness Rate — percent of responses that directly address the query",
    "AUD": "Audit pass rate — privacy/safety/policy checks",
    "CONA": "Consensus Accuracy — debate loop agreement vs ground truth",
    "CORD": "Chain-of-Reasoning Depth — structured step depth achieved vs planned",
    "COV": "Test coverage ratio — capabilities with ≥1 test / total capabilities",
    "CST": "Cost per 1k tokens — effective cost rate",
    "HAL": "Hallucination rate — share of factual claims failing verification",
    "INC": "Incident rate (severity-weighted) — weighted incidents per 100 tasks",
    "LAT": "Latency p50/p95 — end-to-end completion time percentiles",
    "PRI": "Plan/Reason Integrity — required tests passed across functional+governance suites",
    "RFG": "Reflection Gain — error reduction after reflection",
    "RST": "Regression Stability — percent of outputs within tolerance vs baseline",
    "RTI": "Reasoning Transparency Index — derived from sanitized Reasoning Footprints"
  },
  "token_budget": {
    "max_output_tokens": 1000
  },
  "version": 2
}
